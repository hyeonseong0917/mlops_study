# ML을 서비스하기 위한 MLOps

### 기존 ML프로젝트 진행 방식의 한계

- 학습 환경과 배포 환경이 동일하지 않음
- 협업 시 체계적으로 각 모델의 성능, 데이터, 하이퍼 파라미터 등을 관리하는 것이 쉽지 않음
    - ex) 몇 번째로 성능이 좋았던 모델을 얻고 싶을 때
- 타인이 구성했던 모델을 재현 시 각자가 구성했던 구성 환경이 다르기 때문에(pytorch, tensorflow, pip버전 등) 이슈가 발생

### ML 소프트웨어 방법론의 자동화를 위해 DevOps문화를 결합하려는 시도

- 버전관리(git)
- 학습단계 - 테스트 자동화(모델 학습 자동화, 모델 성능 평가 자동화)
- 서빙 단계 - 모니터링(서빙 모델 모니터링, 데이터 변화 모니터링, 시스템 안정성 모니터링)
- DevOps에서 사용했던 ML모델의 개발, 서비스, 운영과정에 필요한 여러 구성 요소들을 결합 ⇒ ML 모델을 효율적으로 개발하고 성공적으로 서비스화하여 운영할 때 필요한 것들을 다룸

### MLOps를 구성하는 요소들과 관련된 오픈소스

- 데이터:
    - 데이터 수집: Spark Streaming, Kafka, Airflow
    - 데이터 저장: Hadoop, S3, MySQL
    - 데이터 관리: 데이터 버전 컨트롤(DVC), Feature Store(Feast)
    - 모델 개발: Jupyter Hub, Docker, Kubeflow ⇒ 격리된 환경에서 개발할 수 있도록
    - 모델 버전 관리: Git(소스코드 형상 관리), MLflow(패키징 된 모델, 모델 성능 metric, 하이퍼 파라미터 관리), Github Action(지속적인 CI/CD), Jenkins
    - 모델 학습 스케줄링 관리: GPU 관리 등을 Grafana와 같은 툴로 모니터링하고 Kubernetes를 이용한 모델 학습 스케줄링
    - 서빙 모니터링
        - 서빙이란?: 기존에 데이터를 추가하고 .predict함수를 이용해 그 예측값을 확인했는데 서버에서 API 형태로 예측값을 제공하는 서비스
        - 서빙의 장점: 더 좋은 서버에서 예측값을 확인할 수 있고 접근성을 높일 수 있음
        - 모델 패키징: API 서버가 os 등 특정 파이썬 패키지에 종속되지 않도록 독립적인 환경인 Docker 컨테이너와 Flask, FastAPI같은 API 프레임워크를 사용할 수 있고
        Kubeflow, seldon-core와 같은 머신러닝에 특화된 API 프레임워크를 이용할 수 있음
        - 서빙 후에도 환경이 제대로 돌아가고 있는지, 성능이 떨어지지는 않는지 메트릭을 확인하고 알람을 받을 수 있게 Prometheus 혹은 Grafana를 사용
    - 파이프라인 매니징
        - 성능확인, A/B테스트 등을 위해 이전 모델 학습 과정 전체가 필요한 경우가 있을 수 있기 때문에 파이프라인 형태로 구성해야 재사용 가능 - Kubeflow, Airlow, argo workflows 등